{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "import pathlib\n",
    "from typing import List, Optional\n",
    "import yaml\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from scipy import linalg\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataloader import *\n",
    "from models import *\n",
    "from utils.builder import build_pipeline\n",
    "from utils.builder import build_metrics\n",
    "from utils.builder import build_models\n",
    "from dataloader.RandomDataset import *\n",
    "from frechet import DiscreteFrechet, euclidean\n",
    "import pickle\n",
    "if __name__ == \"__main__\":\n",
    "  \n",
    "    yaml_f = \"/nas/k8s/dev/research/intern/jhmin/test_project/despeckle/CTD/configs/capella.yaml\"\n",
    "    weight_path =  \"/nas/k8s/dev/research/intern/jhmin/test_project/despeckle/CTD/weights_sar/capella_230926-060602.pkl\"\n",
    "    with open(weight_path, 'rb') as f:\n",
    "            weight = pickle.load(f)\n",
    "    with open(yaml_f) as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    model = build_models(config['model']).cuda()\n",
    "    target_dataset = SynDataset(config['dataset']['src_path'], weight = weight,\n",
    "                                              pipelines = config['degradations'])\n",
    "    # N = RandomDegradationDataset(config['dataset']['src_path'], config['degradations']).num_possible_bins\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Image Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def mkdir(paths):\n",
    "    if not os.path.exists(paths):\n",
    "        os.makedirs(paths)\n",
    "for x in range (len(target_dataset)):\n",
    "    img = target_dataset[x]['input'].permute((1,2,0)).numpy()\n",
    "    \n",
    "    paths = target_dataset[x]['path'][0]\n",
    "    img = np.clip(img,0,255).astype(np.uint8)\n",
    "    paths = paths.split(\"/\")\n",
    "    paths[10] = \"Synthesized_val\"\n",
    "    check = paths[:-1]\n",
    "    check = \"/\".join(check)\n",
    "    paths = \"/\".join(paths)\n",
    "\n",
    "    mkdir(check)\n",
    "    cv2.imwrite(paths,img)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLT로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "old_string = 'hr'\n",
    "# dn_string = 'Capella_1m_test_DN'\n",
    "lr_string = 'lr'\n",
    "save_folder = './Synthesized/'\n",
    "\n",
    "def mkdir(paths):\n",
    "    if not os.path.exists(paths):\n",
    "        os.makedirs(paths)\n",
    "mkdir(save_folder)\n",
    "data = {}\n",
    "for x in range (len(target_dataset)):\n",
    "    data[x] = {}\n",
    "    for key in target_dataset[x]:\n",
    "        if key != 'path':\n",
    "            data[x][key] = np.clip((target_dataset[x][key].permute((1,2,0)).numpy()),0,255).astype(np.uint8)\n",
    "\n",
    "    c_path = target_dataset[x]['path'][0].split(\"/\")[:13]\n",
    "    filename =target_dataset[x]['path'][0].split(\"/\")[-1]\n",
    "    # dn_path = [dn_string if item == old_string else item for item in c_path]\n",
    "    # dn_path = \"/\".join(dn_path)\n",
    "    # dn_path = os.path.join(dn_path)\n",
    "    # real_lr_dn = cv2.imread(dn_path)\n",
    "    lr_path = [lr_string if item == old_string else item for item in c_path]\n",
    "    lr_path = \"/\".join(lr_path)\n",
    "    lr_path = os.path.join(lr_path)\n",
    "    real_lr = cv2.imread(lr_path)\n",
    "    \n",
    "    data[x]['real_lr'] = real_lr\n",
    "    data[x]['path'] = filename\n",
    "    # data[x]['real_dn'] = real_lr_dn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined images saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# 각 이미지의 'label', 'input', 'real_lr' 이미지를 표시하고 저장\n",
    "for image_name, image_data in data.items():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].imshow(image_data['label'])\n",
    "    axes[0].set_title('Label')\n",
    "    axes[1].imshow(image_data['input'])\n",
    "    axes[1].set_title('Input')\n",
    "    axes[2].imshow(image_data['real_lr'])\n",
    "    axes[2].set_title('real_lr')\n",
    "    # axes[3].imshow(image_data['real_dn'])\n",
    "    # axes[3].set_title('real_dn')\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "    \n",
    "    fig.suptitle(f'Label: {image_name}', fontsize=16)\n",
    "    \n",
    "    combined_image_filename = f'{image_data[\"path\"].replace(\".tif\", \".png\")}'\n",
    "    combined_image_filename = os.path.join(save_folder, combined_image_filename)\n",
    "    plt.savefig(combined_image_filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "print('Combined images saved successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize TIF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import tifffile as tiff\n",
    "dirname = \"/nas/k8s/dev/research/intern/jhmin/test_project/Datasets/SAR/Capella_mm1_uint16/\"\n",
    "o_dir = \"/nas/k8s/dev/research/intern/jhmin/test_project/Datasets/SAR/Capella_uint16_Norm/\"\n",
    "\n",
    "\n",
    "def make_dir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "def min_max_normalize(image, percentile=2):\n",
    "    # Input: [H, W, C]\n",
    "        # tif 값의 nodata != 0 인경우\n",
    "    # _mask = np.mean.. line의 !=0 값을 바꿀것.\n",
    "        # nodata = rasterio.open(filename).meta['nodata']\n",
    "    if len(image.shape) != 3:\n",
    "        image = np.expand_dims(image, -1) \n",
    "    image = image.astype('float32')\n",
    "\n",
    "    percent_min = np.percentile(image, percentile, axis=(0, 1))\n",
    "    percent_max = np.percentile(image, 100-percentile, axis=(0, 1))\n",
    "\n",
    "    _mask = np.mean(image, axis=2) != 0\n",
    "    if image.shape[1] * image.shape[0] - np.sum(_mask) > 0:\n",
    "        mdata = np.ma.masked_equal(image, 0, copy=False)\n",
    "        mdata = np.ma.filled(mdata, np.nan)\n",
    "        percent_min = np.nanpercentile(mdata, percentile, axis=(0, 1))\n",
    "\n",
    "    norm = (image-percent_min) / (percent_max - percent_min)\n",
    "    norm[norm < 0] = 0\n",
    "    norm[norm > 1] = 1\n",
    "    norm = (norm * 255).astype('uint8') * _mask[:, :, np.newaxis]\n",
    "    return norm\n",
    "\n",
    "for root, dirs, files in os.walk(dirname):\n",
    "    for filename in files:\n",
    "        dir = root.split(\"/\")[-1]\n",
    "        input_filepath = os.path.join(root,filename)\n",
    "        print(input_filepath)\n",
    "        img = tiff.imread(input_filepath)\n",
    "        norm_img = min_max_normalize(img)\n",
    "        make_dir(os.path.join(o_dir,dir))\n",
    "        output_filepath = os.path.join(o_dir,dir,filename)\n",
    "        tiff.imsave(output_filepath,norm_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tifffile as tiff\n",
    "import cv2\n",
    "dirname = '/nas/k8s/dev/research/intern/jhmin/test_project/Datasets/SAR/Capella_uint16_Norm/Capella_0.5m_resize/'\n",
    "large_size = 2000\n",
    "for root, dirs, files in os.walk(dirname):\n",
    "    for filename in files:\n",
    "        dir = root.split(\"/\")[-1]\n",
    "        input_filepath = os.path.join(root,filename)\n",
    "        \n",
    "        img = cv2.imread(input_filepath)\n",
    "        # print(img.shape, input_filepath)\n",
    "        size, w ,c  = img.shape\n",
    "\n",
    "        if size < large_size:\n",
    "            large_size = size\n",
    "        # print(large_size, input_filepath)\n",
    "\n",
    "print(large_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR values for each image: [9.319925298299902, 9.323173178583872, 9.783847179895995, 10.166962440981678, 10.012589235098176, 12.112449973935064, 8.513173492997385, 12.479843486396142, 10.14720818716691, 11.278899868483535, 11.602040761022408, 9.993059049244618, 8.073365072577252, 10.040855438730997, 9.472114635677274, 10.673141147079859, 9.689687734226723, 9.795273704075228, 11.702085358077913, 10.575506306179998, 12.032714249877078, 11.655096509141881, 9.635203288290583, 10.573478280256163, 9.672966722236575, 10.73560111832647, 10.52708663517478, 10.086421081037454, 7.577844953472551, 11.63895945173898, 9.903175768267298, 9.642284057414178, 11.6722070038381, 9.527114294262152, 10.518443222603695, 11.779416845955337, 10.840763908342089, 10.474005196500894, 10.929500454354091, 10.905317878658394, 10.852487917523717, 10.756469380721418, 10.801521167783974, 10.068727468133556, 9.912308803309337, 11.198052091376635, 10.34534474448025, 9.67898837258609, 7.432280194990693, 10.099112163590565, 8.792488606154109, 9.946681280415397, 10.700463631561002, 11.359200026292216, 12.342504344534342, 9.161141099342423, 12.016694824604253, 10.881216396645259, 9.417802908588582, 10.09633441022931, 9.484352763191099, 9.68662707473177, 10.665450376846945, 9.962864749012613, 8.352559411399977, 10.348524715867452, 8.852795571711784, 10.371807269402236, 10.080682305606157, 11.043185351527878, 11.061176710962473, 11.152999054682553, 7.776589417624723, 10.437180039259212, 10.357487184575572, 10.744045225169199, 10.185930717968033, 10.694744180945685, 10.45621001140785, 10.231548770534676, 10.9292297867878, 10.44449663632641, 8.538886447607455, 10.020192932199288, 9.50640890974957, 9.762994181966734, 12.090535457261694, 7.060298206400787, 9.39813950775402, 9.743161307480776, 9.943708478280973, 10.563729224205785, 11.177908578688644, 9.813037020564204, 10.822802911242103, 9.941255907864374, 9.541146331239656, 9.884589370830382, 10.589367906612694, 8.86003915018572, 9.406973346609464, 9.335328110764392, 9.892473478676262, 9.668303144322852, 8.100202349117918, 10.497991962814533, 7.760396714039111, 11.240235397014908, 7.24064989785828, 9.756205944851242, 9.816948339245979, 9.391306153809332, 9.986905069393405, 9.693744978888635, 10.091024249265763, 9.47216749311342, 10.06764255887141, 10.85223561223065, 9.570092331001035, 9.584559114769855, 10.559200485405976, 9.607910332196019, 9.651445760622295, 10.206547260704223, 9.851628132680563, 10.453763295615094, 10.457852729770584, 10.589699093154877, 9.986394336816332, 11.388444728722373, 9.452643519313789, 10.090176053067196, 10.370005338108442, 10.810865554787522, 11.006331493336166, 10.319657258405584, 11.492463406691208, 9.705793568726058, 8.080025904919, 9.673486952670219, 10.144054174484204, 10.238740717799466, 7.26433866121531, 9.989688012288676, 9.710842789836324, 10.244982591291249, 10.664577744934913, 9.601761018561428, 9.934577844933996, 9.924812075994017]\n",
      "Average PSNR: 10.09612939027154\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "\n",
    "def calculate_psnr(img1, img2):\n",
    "    \"\"\"이미지 간 PSNR 계산\"\"\"\n",
    "    return peak_signal_noise_ratio(img1, img2)\n",
    "\n",
    "def compare_psnr_in_folders(folder1, folder2):\n",
    "\n",
    "    psnr_values = []\n",
    "\n",
    "    # 폴더 내의 이미지 파일 목록 가져오기\n",
    "    images1 = os.listdir(folder1)\n",
    "    images2 = os.listdir(folder2)\n",
    "\n",
    "    # 이미지 파일들 간의 PSNR 계산\n",
    "    for img_name1, img_name2 in zip(images1, images2):\n",
    "        img_path1 = os.path.join(folder1, img_name1)\n",
    "        img_path2 = os.path.join(folder2, img_name2)\n",
    "\n",
    "        # 이미지 읽기\n",
    "        img1 = cv2.imread(img_path1, cv2.IMREAD_COLOR)\n",
    "        h,w,c  = img1.shape\n",
    "        img2 = cv2.imread(img_path2, cv2.IMREAD_COLOR)\n",
    "\n",
    "        img2 = cv2.resize(img2, dsize=(h,w), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # PSNR 계산\n",
    "        psnr_value = calculate_psnr(img1, img2)\n",
    "        psnr_values.append(psnr_value)\n",
    "\n",
    "    # 평균 PSNR 계산\n",
    "    average_psnr = np.mean(psnr_values)\n",
    "\n",
    "    return psnr_values, average_psnr\n",
    "\n",
    "# 두 폴더에 대한 PSNR 비교\n",
    "folder1_path = \"/nas/k8s/dev/research/intern/jhmin/test_project/Datasets/SAR/Capella_uint16_Norm/Capella_0.5m_resize_test/\"  # 폴더1 경로로 수정\n",
    "folder2_path = \"/nas/k8s/dev/research/intern/jhmin/test_project/Datasets/SAR/Capella_uint16_Norm/Capella_1m_test/\"  # 폴더2 경로로 수정\n",
    "\n",
    "psnr_values, average_psnr = compare_psnr_in_folders(folder1_path, folder2_path)\n",
    "\n",
    "print(\"PSNR values for each image:\", psnr_values)\n",
    "print(\"Average PSNR:\", average_psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 600 files [00:07, 83.59 files/s] \n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "input = \"/nas/k8s/dev/research/intern/jhmin/test_project/Datasets/paired_eo/\"\n",
    "output = \"\"\n",
    "splitfolders.ratio(input,input, seed=43, ratio=(0.8,0.1,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7608e-05,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3692e-08, 2.4234e-04, 8.1181e-06,\n",
      "        2.0337e-05, 5.9095e-04, 1.5344e-06, 5.4888e-03, 6.2769e-05, 3.0687e-07,\n",
      "        9.2577e-04, 1.0043e-06, 2.7897e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        5.5795e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        6.2354e-03, 3.7103e-06, 8.9271e-07, 9.7641e-07, 1.5901e-06, 3.8189e-01,\n",
      "        4.2659e-03, 5.6674e-02, 1.0992e-03, 3.4612e-04, 2.1585e-02, 4.7902e-04,\n",
      "        1.1891e-02, 5.6185e-05, 7.1983e-04, 5.7468e-06, 0.0000e+00, 4.1846e-07,\n",
      "        0.0000e+00, 0.0000e+00, 1.6459e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 6.2526e-04, 1.2710e-04, 8.3552e-05, 6.9743e-07, 1.8412e-06,\n",
      "        2.6980e-02, 4.0211e-01, 6.1965e-03, 4.8953e-02, 1.5333e-02, 1.9891e-05,\n",
      "        6.0453e-05, 1.9921e-03, 3.4735e-04, 4.5027e-03, 2.1481e-06, 2.7060e-06,\n",
      "        2.6781e-06, 1.6180e-06, 4.1846e-07])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "fname = \"/nas/k8s/dev/research/intern/jhmin/test_project/despeckle/SRResNet/weights_pipal/settings1.pkl\"\n",
    "with open(fname, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "# 읽어온 데이터 사용\n",
    "print(loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.4021, 0.3819, 0.0567, 0.0490, 0.0270]),\n",
       "indices=tensor([61, 35, 37, 63, 60]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.topk(loaded_data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.float64(1/75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def select_indices(data):\n",
    "    indices = []\n",
    "    for dimension in data:\n",
    "        choice = random.choices(range(len(dimension)), dimension)\n",
    "        indices.append(choice[0])\n",
    "    return indices\n",
    "\n",
    "# 무작위로 선택된 인덱스를 가져옵니다.\n",
    "selected_indices = select_indices(loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = ([0.0927, 0.0898, 0.0831, 0.0569, 0.0471],\n",
    "([ 5,  8, 29,  7, 32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSNR 뽑기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 images with the largest PSNR difference:\n",
      "Top 1: 0280.png - PSNR Difference: 0.382dB\n",
      "Top 2: 0019.png - PSNR Difference: 0.274dB\n",
      "Top 3: 0078.png - PSNR Difference: 0.245dB\n",
      "Top 4: 0063.png - PSNR Difference: 0.228dB\n",
      "Top 5: 0255.png - PSNR Difference: 0.208dB\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# JSON 파일에서 데이터 읽어오기\n",
    "with open('/nas/k8s/dev/research/intern/jhmin/test_project/despeckle/ESRGAN-PyTorch/Test_output/RRDBNet_x4-CTD.json', 'r') as file:\n",
    "    a_data = json.load(file)\n",
    "\n",
    "with open('/nas/k8s/dev/research/intern/jhmin/test_project/despeckle/ESRGAN-PyTorch/Test_output/RRDBNet_x4-uniform.json', 'r') as file:\n",
    "    b_data = json.load(file)\n",
    "\n",
    "psnr_diff_data = []\n",
    "for a_info in a_data:\n",
    "    for b_info in b_data:\n",
    "        if a_info['filename'] == b_info['filename']:\n",
    "            psnr_diff = abs(a_info['psnr'] - b_info['psnr'])\n",
    "            psnr_diff_data.append({'filename': a_info['filename'], 'psnr_diff': psnr_diff})\n",
    "\n",
    "# PSNR 차이 기준으로 정렬\n",
    "sorted_by_psnr_diff = sorted(psnr_diff_data, key=lambda x: x['psnr_diff'], reverse=True)\n",
    "\n",
    "# 상위 5개 이미지 출력\n",
    "print(\"Top 5 images with the largest PSNR difference:\")\n",
    "for i, info in enumerate(sorted_by_psnr_diff[:5], start=1):\n",
    "    print(f'Top {i}: {info[\"filename\"]} - PSNR Difference: {info[\"psnr_diff\"]:.3f}dB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
